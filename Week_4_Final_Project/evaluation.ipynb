{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff0a9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, AutoTokenizer\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"./gpt2-finetuned-nwp-final\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./gpt2-finetuned-nwp-final\")\n",
    "model.eval() # Set model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7623a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"wikitext\", \"wikitext-2-v1\")\n",
    "\n",
    "def tokenize(examples):\n",
    "    return tokenizer(examples[\"text\"], max_length=256, padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_dataset = ds.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd11271",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tokenized_dataset[\"test\"].shuffle(seed=42).range(100)  # Use a smaller subset for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19cf5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DefaultDataCollator\n",
    "data_collator = DefaultDataCollator()\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"./dummy\", per_device_eval_batch_size=1, fp16=True, eval_accumulation_steps=8, remove_unused_columns=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Predict on test set\n",
    "outputs = trainer.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e24d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import top_k_accuracy_score\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    # Shift so model predicts token t+1\n",
    "    shift_logits = torch.tensor(logits)[..., :-1, :].contiguous()\n",
    "    shift_labels = torch.tensor(labels)[..., 1:].contiguous()\n",
    "\n",
    "    # Flatten the tensors\n",
    "    shift_logits = shift_logits.view(-1, shift_logits.size(-1))\n",
    "    shift_labels = shift_labels.view(-1)\n",
    "\n",
    "    # Mask out padding\n",
    "    valid = shift_labels != -100\n",
    "    y_true = shift_labels[valid].numpy()\n",
    "    y_pred = shift_logits[valid].numpy()\n",
    "\n",
    "    # Top-k accuracy\n",
    "    topk_acc = top_k_accuracy_score(y_true, y_pred, k=5, labels=list(range(50257))) # GPT-2 vocab size is 50257\n",
    "\n",
    "    return {\n",
    "        \"top5_accuracy\": topk_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aa25aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "perplexity = load(\"perplexity\")\n",
    "\n",
    "raw_test_texts = test_ds[\"text\"]\n",
    "\n",
    "raw_test_texts = [t for t in test_ds[\"text\"] if t.strip() != \"\"]\n",
    "\n",
    "results = perplexity.compute(\n",
    "    predictions=raw_test_texts,\n",
    "    model_id=\"./gpt2-finetuned-nwp-final\",\n",
    ")\n",
    "\n",
    "print(\"Perplexity:\", results[\"perplexity\"])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
