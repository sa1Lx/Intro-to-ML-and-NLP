# Intro-to-ML-and-NLP
Learner Space course under Web and Coding Club (WnCC), IIT Bombay

# Course Overview
This comprehensive course blends the power of Machine Learning (ML) with the language understanding capabilities of Natural Language Processing (NLP). Designed for aspiring AI engineers, data scientists, and developers, the course begins with the core principles of ML and gradually transitions into the specialized world of NLP.

Exploring python libraries and the core building blocks of NLP: tokenization, stemming, lemmatization, part-of-speech tagging, and named entity recognition.

As the course progresses, there will be diving into deep learning for NLP, understanding recurrent neural networks (RNNs), LSTMs. From there, we transition into the world of Transformers covering key models like BERT.

Using the Hugging Face ecosystem, gaining hands-on experience in fine-tuning pre-trained models for downstream tasks such as sentiment analysis, text classification, question answering, and summarization. The course also introduces Generative Adversarial Networks (GANs) applied to text generation—a challenging and emerging area in NLP.

Throughout the course, will be working on real-world projects that reinforce learning and prepare you for building production-ready NLP applications.

# Course Structure

## Week 1

  Foundations of NLP & Data Processing

    -> Introduction to NLP  
    NLP pipeline overview: tokenization, preprocessing, vectorization, modeling, evaluation.  

    -> Python Libraries  
    NumPy: Numerical operations (arrays, broadcasting, vectorized math).  
    Pandas: Data handling (Series, DataFrames, handling text columns).  
    Text preprocessing using sklearn.  

    -> Regex (Regular Expressions)  
    Basics: pattern matching, wildcards, quantifiers.  
    Practice with Python’s re module.  

## Week 2

  Classical NLP Modeling

    -> Text Vectorization  
    TF-IDF (Term Frequency-Inverse Document Frequency):  
    Concept of bag-of-words vs TF-IDF.  

    -> Logistic Regression for Text Classification  
    Training and evaluating a classifier for sentiment analysis or spam detection.  
    Metrics: Accuracy, Precision, Recall, F1-score.  
    Hands-on: train a TF-IDF + Logistic Regression model.  

    -> Word & Sentence Embeddings  
    Limitations of one-hot and TF-IDF.  
    Word2Vec, GloVe, and FastText.  
    Sentence embeddings (e.g., Sentence-BERT).  

## Week 3

  Deep Learning & Modern NLP

    -> Transformers
    The transformer architecture (attention mechanism, encoder-decoder blocks).
    Key models: BERT, GPT, RoBERTa, etc.
    Pretraining vs fine-tuning.

    -> Hugging Face Library
    Using the transformers library.
    Tokenization, loading pretrained models, pipelines (e.g., pipeline('sentiment-analysis')).
    Fine-tuning on custom data using Trainer API.

    -> Overview of Generative Adversarial Networks

    -> Bonus: Diffusion in NLP
    Overview of Diffusion Models.
    How these are adapted for text generation.

## Week 4

  Final Project

    -> Final NLP Project  

    -> Wrap-Up & Beyond  
    Recap of all topics.  
    Where to go next? (e.g., LLMs, fine-tuning techniques, Reinforcement Learning for NLP)  


